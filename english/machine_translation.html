<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Machine translation</title>
    <meta name="description" content="">
    <meta name="generator" content="VuePress 1.3.0">
    
    
    <link rel="preload" href="/github-nlp-progress/assets/css/0.styles.6033efd5.css" as="style"><link rel="preload" href="/github-nlp-progress/assets/js/app.b20772ac.js" as="script"><link rel="preload" href="/github-nlp-progress/assets/js/2.3456af6e.js" as="script"><link rel="preload" href="/github-nlp-progress/assets/js/3.937c9f03.js" as="script"><link rel="preload" href="/github-nlp-progress/assets/js/24.42cc839c.js" as="script"><link rel="prefetch" href="/github-nlp-progress/assets/js/10.f689590e.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/11.feaa3bcb.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/12.2b17b66d.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/13.1ecc9616.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/14.482ff2f6.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/15.c908a65f.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/16.526d82ab.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/17.ca814de2.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/18.a63c1b3f.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/19.c36f96a3.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/20.9d045ccf.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/21.c81c39a0.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/22.fe5953be.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/23.163ffb04.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/25.7b8b881c.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/26.d0e55d1e.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/27.570a6122.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/28.c6c819d2.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/29.a5689ea7.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/30.d92f9437.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/31.e930da89.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/32.01e0d63d.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/33.c990d921.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/34.623b67c0.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/35.956880b6.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/36.eca657d8.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/37.f4f9eb6e.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/38.29f230d6.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/39.129ccc73.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/4.651aad0d.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/40.5b82b120.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/41.4db3af07.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/42.1dcf5e6f.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/43.a0b31f1b.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/44.256964ad.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/45.6c8f68d1.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/46.9879832f.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/47.c01dc2ea.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/48.bb854260.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/49.2ebc9060.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/5.ffcec782.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/50.c98ac9da.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/51.c4fcf44a.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/52.152ad53d.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/53.83d2918e.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/54.be25bf7b.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/55.ae33356c.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/56.abdb2608.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/57.8f332845.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/58.6fcbc630.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/59.0cdd7b14.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/6.a92588db.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/60.5d2be490.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/7.d8fa3081.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/8.189190f5.js"><link rel="prefetch" href="/github-nlp-progress/assets/js/9.6d7119f7.js">
    <link rel="stylesheet" href="/github-nlp-progress/assets/css/0.styles.6033efd5.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div id="global-layout" data-v-2be041bb><header class="bk-dark" data-v-2be041bb><video autoplay="autoplay" loop="loop" muted="muted" data-v-2be041bb><source src="/github-nlp-progress/assets/media/bk.417d52db.mp4" type="video/mp4" data-v-2be041bb></video> <div data-v-2be041bb><div class="header-content" data-v-2be041bb><h1 data-v-2be041bb>NLP-PROGRESS</h1> <h2 data-v-2be041bb>Repository to trasck the progress in Natural Language Processing (NLP), including the datasets and the current state-of-the-art for the most common NLP tasks.</h2> <a href="#" class="btn" data-v-2be041bb><i class="iconfont icon-github" data-v-2be041bb></i>
                    View on GitHub
                </a></div></div></header> <div class="theme-container no-navbar" data-v-2be041bb><!----> <div class="sidebar-mask"></div> <div class="sidebar-wrap sidebar-wrap-absolute"><!----></div> <main class="page"> <div class="theme-default-content content__default"><h1 id="machine-translation"><a href="#machine-translation" class="header-anchor">#</a> Machine translation</h1> <p>Machine translation is the task of translating a sentence in a source language to a different target language.</p> <p>Results with a * indicate that the mean test score over the the best window based on average dev-set BLEU score over
21 consecutive evaluations is reported as in <a href="https://arxiv.org/abs/1804.09849" target="_blank" rel="noopener noreferrer">Chen et al. (2018)<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</p> <h3 id="wmt-2014-en-de"><a href="#wmt-2014-en-de" class="header-anchor">#</a> WMT 2014 EN-DE</h3> <p>Models are evaluated on the English-German dataset of the Ninth Workshop on Statistical Machine Translation (WMT 2014) based
on BLEU.</p> <table><thead><tr><th>Model</th> <th style="text-align:center;">BLEU</th> <th>Paper / Source</th></tr></thead> <tbody><tr><td>Transformer Big + BT (Edunov et al., 2018)</td> <td style="text-align:center;">35.0</td> <td><a href="https://arxiv.org/pdf/1808.09381.pdf" target="_blank" rel="noopener noreferrer">Understanding Back-Translation at Scale<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>DeepL</td> <td style="text-align:center;">33.3</td> <td><a href="https://www.deepl.com/press.html" target="_blank" rel="noopener noreferrer">DeepL Press release<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>MUSE (Zhao et al., 2019)</td> <td style="text-align:center;">29.9</td> <td><a href="https://arxiv.org/abs/1911.09483" target="_blank" rel="noopener noreferrer">MUSE: Parallel Multi-Scale Attention for Sequence to Sequence Learning<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>DynamicConv (Wu et al., 2019)</td> <td style="text-align:center;">29.7</td> <td><a href="https://arxiv.org/abs/1901.10430" target="_blank" rel="noopener noreferrer">Pay Less Attention With Lightweight and Dynamic Convolutions<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>AdvSoft + Transformer Big (Wang et al., 2019)</td> <td style="text-align:center;">29.52</td> <td><a href="http://proceedings.mlr.press/v97/wang19f/wang19f.pdf" target="_blank" rel="noopener noreferrer">Improving Neural Language Modeling via Adversarial Training<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Transformer Big (Ott et al., 2018)</td> <td style="text-align:center;">29.3</td> <td><a href="https://arxiv.org/abs/1806.00187" target="_blank" rel="noopener noreferrer">Scaling Neural Machine Translation<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>RNMT+ (Chen et al., 2018)</td> <td style="text-align:center;">28.5*</td> <td><a href="https://arxiv.org/abs/1804.09849" target="_blank" rel="noopener noreferrer">The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Transformer Big (Vaswani et al., 2017)</td> <td style="text-align:center;">28.4</td> <td><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">Attention Is All You Need<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Transformer Base (Vaswani et al., 2017)</td> <td style="text-align:center;">27.3</td> <td><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">Attention Is All You Need<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>MoE (Shazeer et al., 2017)</td> <td style="text-align:center;">26.03</td> <td><a href="https://arxiv.org/abs/1701.06538" target="_blank" rel="noopener noreferrer">Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>ConvS2S (Gehring et al., 2017)</td> <td style="text-align:center;">25.16</td> <td><a href="https://arxiv.org/abs/1705.03122" target="_blank" rel="noopener noreferrer">Convolutional Sequence to Sequence Learning<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr></tbody></table> <h3 id="wmt-2014-en-fr"><a href="#wmt-2014-en-fr" class="header-anchor">#</a> WMT 2014 EN-FR</h3> <p>Similarly, models are evaluated on the English-French dataset of the Ninth Workshop on Statistical Machine Translation (WMT 2014) based
on BLEU.</p> <table><thead><tr><th>Model</th> <th style="text-align:center;">BLEU</th> <th>Paper / Source</th></tr></thead> <tbody><tr><td>DeepL</td> <td style="text-align:center;">45.9</td> <td><a href="https://www.deepl.com/press.html" target="_blank" rel="noopener noreferrer">DeepL Press release<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Transformer Big + BT (Edunov et al., 2018)</td> <td style="text-align:center;">45.6</td> <td><a href="https://arxiv.org/pdf/1808.09381.pdf" target="_blank" rel="noopener noreferrer">Understanding Back-Translation at Scale<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>MUSE (Zhao et al., 2019)</td> <td style="text-align:center;">43.5</td> <td><a href="https://arxiv.org/abs/1911.09483" target="_blank" rel="noopener noreferrer">MUSE: Parallel Multi-Scale Attention for Sequence to Sequence Learning<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>DynamicConv (Wu et al., 2019)</td> <td style="text-align:center;">43.2</td> <td><a href="https://arxiv.org/abs/1901.10430" target="_blank" rel="noopener noreferrer">Pay Less Attention With Lightweight and Dynamic Convolutions<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Transformer Big (Ott et al., 2018)</td> <td style="text-align:center;">43.2</td> <td><a href="https://arxiv.org/abs/1806.00187" target="_blank" rel="noopener noreferrer">Scaling Neural Machine Translation<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>RNMT+ (Chen et al., 2018)</td> <td style="text-align:center;">41.0*</td> <td><a href="https://arxiv.org/abs/1804.09849" target="_blank" rel="noopener noreferrer">The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Transformer Big (Vaswani et al., 2017)</td> <td style="text-align:center;">41.0</td> <td><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">Attention Is All You Need<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>MoE (Shazeer et al., 2017)</td> <td style="text-align:center;">40.56</td> <td><a href="https://arxiv.org/abs/1701.06538" target="_blank" rel="noopener noreferrer">Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>ConvS2S (Gehring et al., 2017)</td> <td style="text-align:center;">40.46</td> <td><a href="https://arxiv.org/abs/1705.03122" target="_blank" rel="noopener noreferrer">Convolutional Sequence to Sequence Learning<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr> <tr><td>Transformer Base (Vaswani et al., 2017)</td> <td style="text-align:center;">38.1</td> <td><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">Attention Is All You Need<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></td></tr></tbody></table> <p><a href="/github-nlp-progress/" class="router-link-active">Go back to the README</a></p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div> <footer class="bk-dark" data-v-2be041bb><div class="footer-content" data-v-2be041bb><p data-v-2be041bb>Published with GitHub Pages</p></div></footer></div><div class="global-ui"></div></div>
    <script src="/github-nlp-progress/assets/js/app.b20772ac.js" defer></script><script src="/github-nlp-progress/assets/js/2.3456af6e.js" defer></script><script src="/github-nlp-progress/assets/js/3.937c9f03.js" defer></script><script src="/github-nlp-progress/assets/js/24.42cc839c.js" defer></script>
  </body>
</html>
